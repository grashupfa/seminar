\documentclass[
a4paper,
12pt
]{scrartcl}


\usepackage{tikz}
\usetikzlibrary{arrows,automata}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{ae,aecompl}
\usepackage{amsmath,amssymb,amstext}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{float}
\usepackage{psfrag}
\usepackage{listings}
\usepackage{color}
\usepackage[automark]{scrpage2}
\usepackage{smartdiagram}
\usepackage{ifpdf}
\usepackage{xcolor,colortbl}
\usepackage{epsdice}
\usepackage{pgfplots}
\usepackage{pdfpages}


\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\definecolor{grayself}{rgb}{0.9,0.9,0.9}
\newcommand{\gray}{\cellcolor{grayself}}  %{0.9}

\lstdefinestyle{prism}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstdefinelanguage{Prism}
{
  % list of keywords
  morekeywords={
  bool,C,ceil,const,ctmc,double,dtmc,endinit,endmodule,endrewards, endsystem,F,false,floor,formula,G,global,I,init,int,label,max,mdp,min, module,nondeterministic,P,Pmin,Pmax,prob,probabilistic,R,rate,rewards,Rmin,Rmax,S,stochastic,system,true,U,X
  },
  sensitive=false, % keywords are not case-sensitive
  morecomment=[l]{//}, % l is for line comment
  morecomment=[s]{/*}{*/}, % s is for start and end delimiter
  morestring=[b]" % defines that strings are enclosed in double quotes
}

\lstset{style=prism}

\ifpdf
  \pdfcompresslevel=9
  \usepackage[
    pdftex=true,
    backref,
    pagebackref=false,
    colorlinks=true,
    bookmarks=true,
    bookmarksopen=false,
    bookmarksnumbered=false,
    pdfpagemode=None
  ]{hyperref}
  \DeclareGraphicsExtensions{.pdf}

\else
  \usepackage[dvips]{graphicx}
  \DeclareGraphicsExtensions{.eps}
  \usepackage[
    dvips,
    colorlinks=false
  ]{hyperref}

\fi

\hypersetup{
  pdftitle={},
  pdfauthor={},
  pdfsubject={},
  pdfcreator={Accomplished with LaTeX2e and pdfLaTeX with hyperref-package.},
  pdfproducer={},
  pdfkeywords={}
}

\newcommand{\mygraphics}[3]{
  \begin{center}
    \includegraphics[width=#1, keepaspectratio=true]{#2} \\
    \textbf{#3}
  \end{center}
}

\title{Seminarpaper}

\author{Mario Wagner, 0730223}
\date{Graz, am \today{}}

% \publishers{}

% \thanks{} %% use it instead of footnotes (only on titlepage)

% \dedication{} %% generates a dedication-page after titlepage
 \ohead[]{Seminar paper}

\newcommand\me[1]{ [* {\textbf ME:} #1 *]}
\newcommand\mw[1]{ [* {\textbf MW:} #1 *]}

% LTL operators
\newcommand\true {\operatorname {\mathbf{true}}}
\newcommand\X{ \operatorname {\mathbf{X}}}
\newcommand\G{ \operatorname {\mathbf{G}}}
\newcommand\F{ \operatorname {\mathbf{F}}}
\newcommand\U{ \operatorname {\mathbf{U}}}
\newcommand\Prob[1]{ \operatorname {\mathcal{P}_{#1}}}

\font\domino=domino
\def\die#1{{\domino#1}}

\begin{document}

\pagenumbering{roman}
 \maketitle
 \tableofcontents
 \listoffigures
 \listoftables

\newpage

\pagenumbering{arabic}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%
%%% begin main document
%%%
\section{Introduction}
In the industry, model-driven development techniques are getting more and more important, as you can use them for simulation, documentation, model-checking, performance evaluation and many other things. The main problem with these techniques is the part where the model is constructed, because it is often costly and time consuming. Machine Learning techniques try to ease this by automatically constructing a high level model of an unknown system. These techniques are classified into two different categories, supervised learning and unsupervised learning approaches.

\par Supervised learning is the task of inferring knowledge from a fully labeled training data. In contrast, unsupervised learning is the task of inferring knowledge from an unlabeled dataset. In real-world scenarios the usual case is to deal with gigantic datasets that are only partially labeled. These real-world datasets are difficult to deal with because performing supervised learning is not possible due to lack of training data, and doing unsupervised learning is not cost-effective or beneficiary considering accuracy and precision. The common ground of supervised and unsupervised learning, is the task of inferring knowledge from a small amount of labeled data and a huge amount of unlabeled training data; i.e., \emph{semi-supervised learning}. In other words, semi-supervised learning is making use of that small amount of data (i.e., supervised learning) to do unsupervised learning considerably more accurate.

\par \emph{Active learning} is a special case of semi-supervised learning in which the labeled data is incrementally provided by a continuous interaction between the \emph{learner} and an \emph{oracle}. The oracle can be a user, a system, or a teacher that provides a certain level of insight to supervise the learner by letting it to actively query for labels of unknown data. When the oracle is a system, actively querying it only means the learner is iteratively providing the system with input alphabet and asking for the output alphabet.

%\par This method is commonly used to learn models of reactive systems by actively providing them with external events (i.e., inputs) and observe how they react to them (i.e., outputs). Though, sometimes active learning can be as expensive as manual labeling since not all runs of all systems are inexpensive or repeatable; to exemplify, consider a scenario in which an input sequence triggers a safety critical behaviour of the system (e.g. self-termination).

\par A popular algorithm proposed by Angluin \cite{Angluin.1987} is called L$^*$. A so called \textit{learner} efficiently learns an unknown regular set from an \textit{oracle} by repeatedly asking questions and saving the findings in an observation table. There are two types of questions the learner can ask the oracle. First, she can ask whether a given string is a member of the unknown set (i.e., membership query) to which the oracle replies with yes or no. Second, a conjecture can be made and the oracle answers if the set is correct (i.e., equivalence query). If the set is incorrect, a counterexample is provided. The oracle can also be substituted by a random sampling \textit{teacher}. The outcome of the algorithm is a minimal deterministic finite automaton (DFA).

\par Although L$^*$ is a quite useful automata learning approach, there are also issues with it; first of which is while using L$^*$ the learner either learns the correct system or nothing. Next issue with L$^*$ is actually stated earlier, that is, when it is impossible for some systems to perform some queries for various reasons (e.g. not being cost-effective, safety critical behaviour, expensive overheads, randomly changing behaviour, and etc.). Moreover, there are some difficulties when trying to learn deterministic model of an unknown system; one of which is its randomly changing behaviours. For these reasons, sometimes it is better to construct the stochastic or nondeterministic model of the system under learn by sufficiently observing system's behaviour. Similarly, passive learning (i.e., unsupervised learning) is recently used to learn the somewhat correct model of the system under learn out of its execution traces that represent the actual behaviour of the system.

\par AALERGIA \cite{Mao.} is an interesting passive learning approach to learn a stochastic model of an unknown system. This approach learns a stochastic model by using only previously observed patterns in execution traces of the system for it cannot or may not be queried as in Angluin's algorithm. In contrast to statistical model checking, AALERGIA extracts an explicit probabilistic model, which one can use to verify a large class of properties without the need to re-sample the system. It is crucial to note that learning these kinds of models can represent different views of the underlying system, depending on the input and output actions. Therefore, if we tailor the observations to the properties of interest, our verification will be simpler and more efficient.


\me{You need a paragraph describing what is the structure of your seminar paper like; this seminar paper will study AALERGIA algorithm in detail blah blah blah for which the next section is dedicated to some preliminaries. In section 3 we study .... and finally in section $n$ we conclude.}

\me{right now the introduction is telling a story and it is coherent but not coherent enought; I would like you to go through it and polish it further.}
%%% Section PRELIMINARY
\newpage
\section{Preliminaries}
\subsection{Markov Models}
Assuming Markov property, which states future state of the system is only dependant on the current state and not on the events that occurred before, Markov model is a stochastic model capable of depicting randomly changing systems. There are different types of Markov models, some of which we are going to study in this section.
\subsubsection{Deterministic Labeled Markov Chain}
Markov chain is the simplest variation of Markov models used to model autonomous systems whose states are fully observable. A labeled Markov chain is a tuple $M=(Q,AP,\pi,\tau,L)$ where $Q$ is a finite non-empty set of states, $AP$ a finite non-empty set of atomic propositions, $\Sigma=2^{AP}$ is a finite alphabet, $L:Q\to \Sigma$ is a state labeling function, and $\pi$ is the initial probability distribution as follows
\begin{equation*}
  \pi:Q\to [0,1]~\text{s.t.}~\sum_{q\in Q} \pi(q)=1,
\end{equation*}
and $\tau$ is the transition probability function as follows:
\begin{equation*}
  \tau: Q\times Q \to [0,1]~\text{s.t.}~\forall q \in Q \cdot \sum_{q'\in Q}\tau(q,q')=1.
\end{equation*}
A labeled Markov chain is deterministic (DLMC) if (1) there exist an initial state $q_0\in Q$ such that $\pi(q_0)=1$, and (2) for all $\sigma \in \Sigma$ and from all states $q \in Q$ there exists at most one destination state labeled with $\sigma$ that is $\tau(q,q')>0$ and $L(q')=\sigma$.
\subsubsection{Discrete-Time Markov Chain}
\par A Discrete-Time Markov Chain (DTMC) is a tuple $M=(Q,q_0,AP,\tau,L)$ where $Q$ is a finite non-empty set of states, $q_0\in Q$ is the initial state, $AP$ a finite non-empty set of atomic propositions, $\Sigma=2^{AP}$ is a finite alphabet, $L:Q\to \Sigma$ is a state labeling function, and $\tau$ is the transition probability function as follows:
\begin{equation*}
  \tau: Q\times Q \to [0,1]~\text{s.t.}~\forall q \in Q \cdot \sum_{q'\in Q}\tau(q,q')=1.
\end{equation*}
DTMC is actually representing a stochastic processes in discrete time $n \in \mathbb{N}$ as a sequence of random variables $Q={q_n}$. We refer to $q_n$ as the state of process at time $n$, with $q_0$ denoting the initial state. If the random variable $q_i$ takes values in discrete space such as integers $\mathbb{Z}$, then the we are dealing with a discrete-valued stochastic process.
\subsubsection{Markov Decision Process}
Markov Decision Process (MDP) is another variation of Markov models, used to model non-autonomous (controlled) systems whose states are fully observable. An MDP is an extended DTMC such that it allows both probabilistic and non-deterministic behaviour. MDP is a tuple $M=(Q, q_0, AP, \tau, L)$ where $Q$ is a finite non-empty set of states, $q_0$ is the initial state, $AP$ is a finite non-empty set of atomic propositions, $\Sigma = 2^{AP}$ is a finite alphabet, $L:Q \to \Sigma$ is a state labeling function, and $\tau: Q \times AP \times Q \to [0,1]$ is the partial probabilistic transition function defined for all $q$ and $\sigma$ where $\sigma \in L(q)$.
\subsection{PRISM Model Checker}
Dealing with deterministic models it is easy to associate states with strings. Despite the fact that it is not a one-to-one association it is an effective lexicographical representation for not only it is possible to identify a particular state by having a string belonging to set of all strings emanates from it but it also is possible to denote an arbitrary string by a particular state.
A path over the states $q_0, \dots, q_n$ of a state labeled deterministic Markovian model $M$ gives rise to a trace $s = \sigma_1, \dots, s_n$ whose occurrence probability is defined by $\Prob{M}(s)$ as:
\begin{equation*}
  \Prob{M}(s) = \prod_{i=0}^{n-1}\tau(q_i,q_{i+1}),
\end{equation*}
Meanwhile, for non-deterministic Markovian models such as MDP it is also possible to perform Monte-Carlo simulation to estimate the occurrence probability of a trace.
\par PRISM model checker harnesses above described approaches to verify the correctness of stochastic properties of randomly changing systems over their stochastic models. These stochastic properties can be formally formulated by Probabilistic LTL which we are going to study in the next subsection.
\subsubsection{Probabilistic Linear Temporal Logic}
Modal and temporal properties of Markovian models are difficult to formulate because they represent randomly changing systems. Meanwhile, LTL is a modal temporal logic best suited to formally express the properties of reactive systems. In this section, we study a probability extended LTL that is suited to formulate the properties of Markovian models.
\par Linear temporal logic over set of atomic propositions $AP$ is defined by the following syntax:
\begin{multline*}
  \varphi ::= \true~|~a~|~\varphi_1 \land \varphi_2~|~\neg \varphi~|~\X \varphi~|~\G \varphi~|~\F \varphi~|~\varphi_1 \U \varphi_2 \\
  (a \in AP)
\end{multline*}
The syntax of Probabilistic LTL (PLTL) is defined as:
\begin{equation*}
  \phi ::= \Prob{\bowtie r} (\varphi)
\end{equation*}
where $\varphi$ is an LTL property, $\bowtie$ is a comparison operator $\{\leq, <, =, \geq, >\}$ and $r \in [0,1]$ is a confidence threshold.
Semantic of a PLTL can be defined over a deterministic Markovian model $M$ as:
\begin{equation*}
  M \models \Prob{\bowtie r}(\varphi)~\text{iff}~ \Prob{M}(\varphi) \bowtie r,
\end{equation*}
where $\Prob{M}(\varphi)$ denotes $\Prob{M}(\{s~|~s \models \varphi \})$ meaning a string belonging to $M$ models $\varphi$.
\subsubsection{Dice Model} \label{section:diceprograms}
The first and simpler example we are going to use is a PRISM model of a simple probabilistic algorithm, the dice model\cite{KY76}. Figure~\ref{fig:dice} shows the states and the probability of the state transitions. We start at an initial state \textit{S} and we toss a coin at each step, giving us a 50 percent chance of transiting to each of the two following states. The algorithm ends at the leafs of the tree, which represent the values of the dice.

\begin{figure}[ht!]
  \centering
\begin{tikzpicture}[level/.style={sibling distance=60mm/#1, level distance = 1.75cm, -latex}]
\node [circle,draw] (0) {S}
    child
    {
        node [circle,draw] (1) {H}
        child
        {
            node [circle,draw] (3) {H}
            child
            {
                node (d1) {\Large \epsdice{1}} edge from parent node[above left]{0.5}
            }
            edge from parent node[above left]{0.5}
        }
        child
        {
            node [circle,draw] (4) {T}
            child
            {
                node (d2) {\Large \epsdice{2}} edge from parent node[above left]{0.5}
            }
            child
            {
                node (d3) {\Large \epsdice{3}} edge from parent node[above right]{0.5}
            }
            edge from parent node[above right]{0.5}
        }
        edge from parent node[above left]{0.5}
  }
  child
  {
    node [circle,draw] (2) {T}
    child
    {
        node [circle,draw] (5) {H}
        child
        {
            node (d4) {\Large \epsdice{4}} edge from parent node[above left]{0.5}
        }
        child
        {
            node (d5) {\Large \epsdice{5}} edge from parent node[above right]{0.5}
        }
        edge from parent node[above left]{0.5}
    }
    child
    {
        node [circle,draw] (6) {T}
        child
        {
            node (d6) {\Large \epsdice{6}} edge from parent node[above right]{0.5}
        }
        edge from parent node[above right]{0.5}
    }
    edge from parent node[above right]{0.5}
  };
  \path [>=latex',->,line join=bevel, auto, midway, label]
    (3) edge [bend right] node [below right] {$0.5$} (1)
    (6) edge [bend left] node {$0.5$} (2);

\end{tikzpicture}
  \caption{The outcome of a toss of a die generated by randomly throwing a fair coin.}\label{fig:dice}
\end{figure}

The source code of the dice PRISM model is shown in figure~\ref{fig:dicemodel}. At the beginning, the code indicates that it is describing a discrete-time Markov chain (DTMC). The source code shows a single PRISM module called dice. The variable \textit{s}, which represents the state of the system, can take the values from 0 to 7 and is initialised with the value 0 (line~\ref{dicemodel:s}). The variable \textit{d}, which represents the value of the dice, can range from 0 to 6 and is also initialised with the value 0, meaning that the dice has no value yet (line~\ref{dicemodel:d}).
Each line depicts a state and the probabilities of the transitions, e.g. line~\ref{dicemodel:s1} shows there is a probability of 0.5 of transiting to state 3 or state 4 if we are currently in state 1. The model ends if a value is assigned to the dice, as there are no further transitions from that point on.

\begin{figure}[ht!]
\begin{lstlisting}[language=Prism, ,escapechar=|]
dtmc

module dice

	// local state
	s : [0..7] init 0; |\label{dicemodel:s}|
	// value of the dice
	d : [0..6] init 0;  |\label{dicemodel:d}|
	
	[] s=0 -> 0.5 : (s'=1) + 0.5 : (s'=2);
	[] s=1 -> 0.5 : (s'=3) + 0.5 : (s'=4); |\label{dicemodel:s1}|
	[] s=2 -> 0.5 : (s'=5) + 0.5 : (s'=6);
	[] s=3 -> 0.5 : (s'=1) + 0.5 : (s'=7) & (d'=1);
	[] s=4 -> 0.5 : (s'=7) & (d'=2) + 0.5 : (s'=7) & (d'=3);
	[] s=5 -> 0.5 : (s'=7) & (d'=4) + 0.5 : (s'=7) & (d'=5);
	[] s=6 -> 0.5 : (s'=2) + 0.5 : (s'=7) & (d'=6);
	[] s=7 -> (s'=7);
	
endmodule

\end{lstlisting}
\caption{The PRISM Dice Model}
\label{fig:dicemodel}
\end{figure}

\subsubsection{Herman's Self-Stabilisation Algorithm}
The running example we are going to use in this paper (unless explicitly stated otherwise) is a PRISM model of Herman's self-stabilising algorithm, as described in \cite{Kwiatkowska.2012}. The algorithm guarantees that the system recovers from faults in a certain amount of time. Although it is certain that the system self-stabilises eventually, it is very hard to analyse the maximum execution time, which depicts the worst case scenario in this case.
\par Herman's algorithm works with a network of an odd number of identical processes in a ring, ordered anticlockwise. The processes work synchronously and possess a token, which is passed around the ring. The result of a random coin toss decides whether the process keeps the token or passes it on to its neighbour. If a process holds two tokens, they are eliminated. The result is a stable system, where each process has exactly one token and the tokens are passed around forever in the ring. In order to analyse the correctness and the performance of the proposed model, the authors use the tool PRISM Model Checker and invoke probabilistic model checking methods on the model.
\par The proposed methods worked well and proved the correctness of the algorithm. Their findings on the maximum execution time showed, that having 3 tokens, spaced evenly around the ring, always produced the worst-case behaviour. It is stated that probabilistic model checking is extremely useful for checking models of this kind, because simple tools, languages and techniques are provided to model the system. Also, an exhaustive analysis can be done, as opposed to other simulation techniques such as the Monte Carlo simulation. A disadvantage is the restriction of probabilistic model checking to finite state models. Furthermore, the size of the models under analysis are limited to the amount of time and space available.
\par The source code of the model is shown in figure~\ref{fig:hermanmodel}. In this case, seven processes are used in the ring. The step notation in line~\ref{hermanmodel:step} forces all processes to synchronise. The state of each process is depicted by a single two-valued variable (x1-x3). Initially, the value is 1 for all processes. The implementation of this model is straightforward and it is used as a data generator for the input of the AALERGIA implementation.

\begin{figure}[ht!]
\begin{lstlisting}[language=Prism, ,escapechar=|]
dtmc

// module for process 1
module process1

	x1 : [0..1] init 1;
	
	[step] (x1=x3) -> 0.5 : (x1'=0) + 0.5 : (x1'=1); |\label{hermanmodel:step}|
	[step] !(x1=x3) -> (x1'=x3);
	
endmodule

// add further processes through renaming
module process2 = process1[x1=x2, x3=x1 ] endmodule
module process3 = process1[x1=x3, x3=x2 ] endmodule


\end{lstlisting}
\caption{The Prism Herman 3 Model}
\label{fig:hermanmodel}
\end{figure}

\subsection{AALERGIA}
ALERGIA\cite{Carrasco.1994} was introduced by Rafael C. Carrasco and Jose Oncina in 1994. They proposed an algorithm which is capable of identifying any stochastic deterministic regular language by using a prefix tree acceptor and merging the states in O(|S|\textsuperscript{3}), where |S| is the size of the sample. This is especially useful for learning automaton in realistic situations. They based their approach on previous work from Oncina\cite{Oncina92}. ALERGIA has been extended in many ways, one of many is called AALERGIA\cite{Mao.}.
\par The reason for creating AALERGIA was to show that the methods for learning probabilistic automata can be adapted for learning Markov Chain system models for verification. The algorithm also leads to stronger consistency for learning in the limit than previous implementations and the authors analyse how the convergence of the learned model relates to the convergence of probability estimates for system properties. This enables us to use the learned model for probabilistic linear temporal logic (PLTL) model checking.
\par However, there is still room for improvement, as shown by the winning team\cite{Shibata_the11th} in a competition called PAutomaC\footnote{hai.cs.umbc.edu/icgi2012/challenge/Pautomac/index.php}. They introduced a new criterion for merging states based on marginal probability by greedily merging states if it increases the probability of the automaton.
\par In this paper, we take AALERGIA and the provided MATLAB implementation\footnote{http://mi.cs.aau.dk/code/aalergia}, implement it in python and experiment with it. In order to get a better idea of the way the implementation works, we will describe it in detail and a running example for better replicability is used throughout this section. The implementation of the algorithm consists of several parts, which are depicted in the figure~\ref{fig:diaAalergia}.

\begin{figure}[H]
\begin{center}
    \smartdiagramset{
        back arrow disabled=true,
        module minimum width=2cm,
    module minimum height=2cm,
    module x sep=3cm,
    text width=2cm,
    }
   \smartdiagram[flow diagram:horizontal]{Training Data, Prefix Tree Acceptor, Golden Section Search, {\tiny AALERGIA}, DLMC}
\end{center}
    \captionof{figure}{The Flow Diagram AALERGIA}
     \label{fig:diaAalergia}
\end{figure}

\subsubsection{Training Data}
The data used to learn the Deterministic Labeled Markov Chain (DLMC) is supplied in the form of a comma separated values file, which contains the training set and the alphabet to be used. The alphabet consists of a finite 1$\times$N-cell array, where each column contains one letter in the alphabet. The training set consist of a finite N$\times$1-cell array, where each row contains sequences of symbols generated from the model, separated by commas.
\paragraph{Dataset Generator} It is easy to generate datasets by using the command line version of PRISM. It is possible to generate random paths through a model by specifying the model file, an output file and the path to be generated (for instance, how many steps should be processed). The output file can then be used as input file for the AALERGIA implementation.
\par The running example we are going to use is a self-stabilizing ring network with 3 processes.
Table~\ref{table:trainingsSet} shows the beginning of the training set, generated by the PRISM modelchecker, which contains 50 Sequences in total.  In our case, each symbol in the training set represents the states in the ring at a given moment. For example, the symbol 001 shows that process 3 is in the state 1 and process 1 and 2 are in the state 0.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|}
\hline
\gray & \gray  1                                 \\ \hline
\gray 1& 000,001,                                    \\ \hline
\gray 2& 000,011,100,010,101,010,001,100,010,101,   \\ \hline
\gray 3& 000,101,                                    \\ \hline
\gray 4& 000,111,010,001,110,011,101,010,001,110,011, \\ \hline
\gray 5& 000,111,011,101,110,001,                    \\ \hline
\gray 6& 000,101,010,101,110,011,100,011,101,110,    \\ \hline
\end{tabular}
\caption{The Training set}
\label{table:trainingsSet}
\end{table}

Table~\ref{table:alphabet} shows the alphabet, which consists of 8 symbols from 000 to 111.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\gray & \gray 1 & \gray 2 & \gray 3 & \gray 4 & \gray 5 & \gray 6 & \gray 7 & \gray 8 \\ \hline
\gray 1 & 000 & 001 & 010 & 011 & 100 & 101 & 110 & 111 \\ \hline
\end{tabular}
\caption{The Alphabet}
\label{table:alphabet}
\end{table}

\subsubsection{Frequency Prefix Tree Acceptor}
After loading the training set and the alphabet into the workspace, the Frequency Prefix Tree Acceptor (FPTA) is created. A deterministic frequency finite automaton (DFFA) is a tuple $A = \langle \Sigma, Q, I\textsubscript{fr}, F\textsubscript{fr}, \delta\textsubscript{fr}, \delta \rangle$ where $ \Sigma $ = the finite alphabet, $Q$ = the finite set of states, $I\textsubscript{fr}$ = the initial state frequencies, $F\textsubscript{fr}$ = the final state frequencies, $\delta\textsubscript{fr}$ = the frequency transition function and $ \delta$ = the transition function.

Figure~\ref{fig:fptadice} shows how a simplified FPTA for the in section~\ref{section:diceprograms} described dice model looks like. The sample S is a multiset of size 20. S = \{(SH,1), (SHHH,1), (SHHH\epsdice{1},1), (SHH\epsdice{1},2), (SHH\epsdice{1}\epsdice{1},1), (SHT,2), (SHT\epsdice{2},1), (SHT\epsdice{2}\epsdice{2},1), (SHT\epsdice{3},1), (ST,1), (STH,2), (STH\epsdice{4},1), (STH\epsdice{5},1), (STT,2), (STT\epsdice{6},2)\}. The letter H stands for heads, the letter T stands for tails and \epsdice{1} to \epsdice{6} stands for the different dice values. The numbers in the states indicate the count of the occurrences of the event, whereas the numbers on the transitions illustrate the count of all events below it.

\begin{figure}[ht!]
  \centering
\begin{tikzpicture}[>=latex',->,line join=bevel,level/.style={sibling distance=80mm/#1, level distance = 2cm}]
\node [circle,draw] (s){S}
    child
    {
        node [draw] (h) {H(1)}
        child
        {
            node [draw] (hh) {H(0)}
            child
            {
                node [draw] (hhh) {H(1)}
                child
                {
                    node (hhhd1) {\epsdice{1}(1)} edge from parent node[left]{1}
                }
                edge from parent node[above left]{2}
            }
            child
            {
                node (hhd1) {\epsdice{1}(2)}
                child
                {
                    node (hhd1d1) {\epsdice{1}(1)} edge from parent node[left]{1}
                }
                edge from parent node[above right]{3}
            }
            edge from parent node[above left]{5}
        }
        child
        {
            node [draw] (ht) {T(2)}
            child
            {
                node (htd2) {\epsdice{2}(1)}
                child
                {
                    node (htd2d2) {\epsdice{2}(1)} edge from parent node[above left]{1}
                }
                edge from parent node[above left]{2}
            }
            child
            {
                node (htd3) {\epsdice{3}(1)} edge from parent node[above right]{1}
            }
            edge from parent node[above right]{5}
        }
        edge from parent node[above left]{11}
    }
    child
    {
        node [draw] (t) {T(1)}
        child
        {
            node [draw] (th) {H(2)}
            child
            {
                node (ttd4) {\epsdice{4}(1)} edge from parent node[above left]{1}
            }
            child
            {
                node (ttd5) {\epsdice{5}(1)} edge from parent node[above right]{1}
            }
            edge from parent node[above left]{4}
        }
        child
        {
            node [draw] (tt) {T(2)}
            child
            {
                node (ttd6) {\epsdice{6}(2)} edge from parent node[left]{2}
            }
            edge from parent node[above right]{4}
        }
        edge from parent node[above right]{9}
    };
\end{tikzpicture}
  \caption{The FPTA for the DICE model}\label{fig:fptadice}
\end{figure}

\par Algorithm~\ref{alg:fpta} shows how the creation of the FPTA is implemented in the AALERGIA package. The code starts by sorting the training set and by removing double occurrences (line~\ref{fpta:sort}).
After that, a for-loop iterates through the sorted strings and splits them at each comma (line~\ref{fpta:BeginForPrefix} -~\ref{fpta:EndForPrefix}).
This creates all the prefixes from the training set and adds them to the cell array named \emph{prefix}, as shown in Table~\ref{table:prefix}.
\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|}
\hline
\gray & \gray  1                                 \\ \hline
\gray 1&000,000,010,001,100,011,101,110,001,110,001,110,011,101,010,001,100,011,100,010,001,   \\ \hline
\gray 2&000,000,010,001,100,011,101,110,001,110,001,110,011,101,010,001,100,011,100,010,   \\ \hline
\gray 3&000,000,010,001,100,011,101,110,001,110,001,110,011,101,010,001,100,011,100,   \\ \hline
\gray 4&000,000,010,001,100,011,101,110,001,110,001,110,011,101,010,001,100,011,   \\ \hline
\gray 5&000,000,010,001,100,011,101,110,001,110,001,110,011,101,010,001,100,   \\ \hline
\gray 6&000,000,010,001,100,011,101,110,001,110,001,110,011,101,010,001,   \\ \hline
\gray 7&000,000,010,001,100,011,101,110,001,110,001,110,011,101,010,   \\ \hline
\gray 8&000,000,010,001,100,011,101,110,001,110,001,110,011,101,   \\ \hline
\gray 9&000,000,010,001,100,011,101,110,001,110,001,110,011,   \\ \hline
\gray 10&000,000,010,001,100,011,101,110,001,110,001,110,   \\ \hline
\gray 11&000,000,010,001,100,011,101,110,001,110,001,   \\ \hline
\end{tabular}
\caption{The Prefixes}
\label{table:prefix}
\end{table}

\begin{algorithm}[]
\caption{Create the FPTA}\label{alg:fpta}
\begin{algorithmic}[1]
\item \textbf{Input:} the $\sum$ and a set of strings S (training data)
\item \textbf{Output:} a DFFA A and a sorted set of strings U

\State $\textit{U} \gets \text{sort}(\textit{S})$ \label{fpta:sort}
\State $\textit{prefixes} \gets \textit{U}$
\State $\textit{F\textsubscript{fr}} \gets \text{string\_count}(\textit{U})$
\For{$\texttt{u} \in \texttt{U}$} \label{fpta:BeginForPrefix}
        \State $\textit{index} \gets \text{find positions of ``,'' in }\textit{u}$

        \While{$index > 0$}
          \State $\textit{substr} \gets \textit{substring(1:index)}$
         \If {$\textit{substr} \not\in \textit{prefix}$}
   	 \State $\textit{prefixes(end+1)} \gets \textit{substr}$
        \EndIf
           \State $\textit{index} \gets \textit{index-1}$
       \EndWhile
\EndFor \label{fpta:EndForPrefix}

\State $\textit{prefixes} \gets \text{width\_first\_sort}(\textit{prefixes})$ \label{fpta:widthSort}
\State $\textit{predecessor} \gets \text{find\_predecessor}(\textit{prefixes})$ \label{fpta:findPredecessor}

\For{$\texttt{p} \in \texttt{prefixes}$} \label{fpta:BeginForFreq}
\State $\textit{sym} \gets \textit{get\_symbol(p)}$
\State $\textit{pre} \gets \textit{predecessor(p)}$

\State $\textit{freq\_trans\_matrix\textsuperscript{1} (pre, sym)} \gets \textit{predecessor(p)}$
\State $\textit{frequency\_transition} \gets \textit{freq\_trans\_matrix\textsuperscript{2} (pre, sym)} $
\State $\textit{frequency\_transition} \gets \textit{frequency\_transition} + \textit{frequency(p)}$

 \While{$pre$}
          \State update\_freq\_trans\_matrix(\textit{p, pre})
          \State $\textit{pre} \gets \textit{predecessor(p)}$
   \EndWhile

\EndFor \label{fpta:EndForFreq}

\State $\textit{init\_states} \gets  \textit{freq\_trans\_matrix\textsuperscript{1}(1, all)}$
\State \Return \textit{A}  \label{fpta:return}
\end{algorithmic}
\end{algorithm}

In our example, the dimension of  \emph{prefix} is 494x1 and contains all unique prefixes of the training set for further evaluation.
The cell array \emph{prefix} is sorted by width-first-sort (line~\ref{fpta:widthSort}). The shortest strings are at the beginning of the array and the largest at the end of the array, as shown in Table~\ref{table:sortPrefix}.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|}
\hline
\gray & \gray  1                                 \\ \hline
\gray 1&000,         \\ \hline
\gray 2&000,000,     \\ \hline
\gray 3&000,001,     \\ \hline
\gray 4&000,010,     \\ \hline
\gray 5&000,011,     \\ \hline
\gray 6&000,100,     \\ \hline
\gray 7&000,101,     \\ \hline
\gray 8&000,110,     \\ \hline
\gray 9&000,111,     \\ \hline
\gray 10&000,000,010, \\ \hline
\gray 11&000,000,100, \\ \hline
\gray 12&000,000,111, \\ \hline
\gray 13&000,001,100, \\ \hline
\gray 14&000,001,110, \\ \hline
\end{tabular}
\caption{The Sorted Prefix Array}
\label{table:sortPrefix}
\end{table}

The function \emph{find\_predecessor} searches through the \emph{prefixes} array and saves all the predecessors in the corresponding array (line~\ref{fpta:widthSort}). In the end, a for-loop over all the prefixes is executed in order to find all transitions and their frequencies respectively. The values are saved into the \emph{freq\_trans\_matrix}  (line~\ref{fpta:BeginForFreq} -~\ref{fpta:EndForFreq}). This Matrix contains 2 elements: the first element is the transition matrix, which contains all the transition between the states. The second element is a matrix, which contains all the frequencies between the states.

The returned object is a class, which models the DFFA (line~\ref{fpta:return}). It has the following members:
\begin{itemize}
      \item a finite set of states
      \item the labels of the states
      \item the alphabet
      \item the initial state
      \item the initial state frequency
      \item the final state frequency
      \item the frequency transition matrix
      \item RED (later used for merging) \me{be more comprehensive about RED set}
      \item BLUE (later used for merging) \me{likewise}
   \end{itemize}

Table~\ref{table:transitionMatrix} shows how the first element of the frequency transition matrix (the transition matrix) is structured. The columns represent the 8 symbols, the rows the different states. For example,  row number 2, column 1 shows the number 3. This indicates, that state 2 and symbol 1 lead to state 3. The second element of the frequency transition matrix has the same dimensions as the first element and follows the same logic, but instead of transitions it contains the frequencies.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\gray &\gray 1 & \gray 2  & \gray 3  & \gray 4 & \gray 5  & \gray 6  & \gray 7  & \gray 8  \\ \hline
\gray 1&2 & 0  & 0  & 0 & 0  & 0  & 0  & 0  \\ \hline
\gray 2&3 & 4  & 5  & 6 & 7  & 8  & 9  & 10 \\ \hline
\gray 3&0 & 0  & 11 & 0 & 12 & 0  & 0  & 13 \\ \hline
\gray 4&0 & 0  & 0  & 0 & 14 & 0  & 15 & 0  \\ \hline
\gray 5&0 & 16 & 0  & 0 & 0  & 17 & 0  & 0  \\ \hline
\end{tabular}
\caption{The Transition Matrix}
\label{table:transitionMatrix}
\end{table}

\subsubsection{Normalization}

The algorithm~\ref{alg:normalize} shows how a DFFA is converted into a deterministic probabilistic finite automaton (DPFA). The computation is pretty straightforward. As input, the algorithm takes a well defined DFFA, that means that the number of strings entering and leaving a given state is identical. The probabilistic transition matrix (line~\ref{normalize:ptm}) is identical to the frequency transition matrix, but its second element contains the probabilities of the transitions instead of the frequencies of the transitions.

The algorithm searches through the frequency transition matrix, sums up the frequencies of the transitions and adds them to the frequency of the state itself in order to get the total number of frequencies (line~\ref{normalize:sum}). Following that, the frequency of each transition and of the state is divided by the total number of total frequencies, which results in the corresponding probabilities for the transitions. (line~\ref{normalize:divide}).

\begin{algorithm}[H]
\caption{Create a DPFA from a DFFA}\label{alg:normalize}
\begin{algorithmic}[1]
\item \textbf{Input:} a well defined DFFA
\item \textbf{Output:} corresponding DPFA

\For{$q \in Q$}
        \State $\textit{freq\_state} \gets \textit{dffa.finalStateFrequency(q)}$
        \State $\textit{ptm\textsuperscript{1}} \gets \textit{dffa.frequencyTransitionMatrix\textsuperscript{1}}$ \label{normalize:ptm}
         \State $\textit{freq\_trans} \gets \textit{dffa.frequencyTransitionMatrix\textsuperscript{2}(q, all)}$
         \State $\textit{freq\_total} \gets \textit{freq\_trans + freq\_state}$  \label{normalize:sum}

         \If {$\textit{freq\_total} > 0$}
   	 \State $\textit{ptm\textsuperscript{2}(node, index)} \gets \frac{freq\_trans}{freq\_total}$ \label{normalize:divide}
   	  \State $\textit{fsp(q)} \gets \frac{freq\_state}{freq\_total}$
       \EndIf
\EndFor
\State \Return \textit{DPFA(dffa, fsp, ptm)}
\end{algorithmic}
\end{algorithm}

\subsubsection{Golden Section Search}

First, we need to search for a left and right border of $\varepsilon$ in order to get a region for our golden section search. This is done by the following algorithm~\ref{alg:findregion}. In order to save space, the algorithm only explains how to find the left border of the region. The right border is found the same way, with some minor modifications. The algorithm iteratively calculates BIC-scores for the values of $\varepsilon$. For each run of the while-loop, the $\varepsilon$ is multiplied by 0.5 until a left border is found. If the new $\varepsilon$ produces a Bayesian Information Criterion(BIC)-score larger than the previous $\varepsilon$ (line~\ref{findregion:scorelarger}), it essentially means that we found a right border, but the left border is further to the left and we need to search again. If the new score is the same as the old score  (line~\ref{findregion:scorethesame}), we search again. If the value of the score doesn't change for 5 consecutive tries, we break the loop and take the last value of $\varepsilon$ as our left border. Last but not least, if the new score is smaller than the old score (line~\ref{findregion:scoresmaller}), we found the left border and can continue searching for the right border (not shown in the pseudo code).
\paragraph{BIC Score} This is a measure that can be used to evaluate the learned model. It creates a score that is calculated on the likelihood minus a penalty term for the model complexity. The BIC score of a given DLMC A given data $S[n]$ is defined in formula~\ref{eq:bic}

  \begin{equation} \label{eq:bic}
  BIC(A | S[n]) := log(P_A(S[n])) - 1/2 | A | log(N)
  \end{equation}

In this formula, $|A|$ depicts the size of A and $N = \sum l_i$ is the total size of the data.

\begin{algorithm}[H]
\caption{Find $\varepsilon$-region}\label{alg:findregion}
\begin{algorithmic}[1]
\item \textbf{Input:} the DFFA
\item \textbf{Output:} the region for $\varepsilon$, scores, epsilon\_values

\State $\varepsilon \gets \textit{1}$
\State \textit{score} $\gets$ calculate\_BIC\_Score($\varepsilon$, \textit{dffa})
\State $new\_\varepsilon \gets \varepsilon * 0.5$

 \While{$new\_\varepsilon > 0$}

       \State \textit{new\_score} $\gets$ calculate\_BIC\_score(new\_$\varepsilon$, \textit{dffa})

         \If {\textit{new\_score > score}}  \label{findregion:scorelarger}
         \State $\textit{region\_right} \gets \varepsilon$
         \State $\varepsilon \gets new\_\varepsilon$
         \State $ new\_\varepsilon \gets new\_\varepsilon * 0.5$
         \State $\textit{score} \gets \textit{new\_score} $

         \ElsIf {\textit{new\_score = score}} \Comment{do this max. 5 times} \label{findregion:scorethesame}
   	 \State $\varepsilon \gets new\_\varepsilon$
         \State $ new\_\varepsilon \gets new\_\varepsilon * 0.5$
         \State $\textit{score} \gets \textit{new\_score} $

      \Else \label{findregion:scoresmaller}
      \State $\textit{region\_left} \gets new\_\varepsilon$
        \State break
       \EndIf

  \EndWhile

  \State ...
  \State ...

\State \Return \textit{region\_right, region\_left}
\end{algorithmic}
\end{algorithm}

Table~\ref{table:region} shows the values of the left and right border of $\varepsilon$. The algorithm ran only once for the left border ($\varepsilon$ startes with 1 and is halfed every run) and 5 times for the right border, since the scores always stayed the same. Table~\ref{table:bicscores} shows the BIC scores and table~\ref{table:epsilonvalues} shows the corresponding $\varepsilon$ values. For example, we calculated the BIC score for $\varepsilon = 0.5$ and the result was $-1.5769e+03$.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|l|}
\hline
\gray &\gray 1 & \gray 2 \\ \hline
\gray 1&0.5 & 64 \\ \hline
\end{tabular}
\caption{The Search Region}
\label{table:region}
\end{table}

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\gray &\gray 1 & \gray 2 & \gray 3 & \gray 4 & \gray 5 & \gray 6 & \gray 7 & \gray 8 \\ \hline
\gray 1&-840.608 & -1.5769e+03 & -840.608 & -840.608 & -840.608 & -840.608 & -840.608 & -840.608 \\ \hline
\end{tabular}
\caption{The BIC scores}
\label{table:bicscores}
\end{table}

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|l|l|l|l|l|l|l|}
\hline
\gray &\gray 1 & \gray 2 & \gray 3 & \gray 4 & \gray 5 & \gray 6 & \gray 7 & \gray 8 \\ \hline
\gray 1&1 & 0.5 & 2 & 4 & 8 & 16 & 32 & 64 \\ \hline
\end{tabular}
\caption{The Epsilon values}
\label{table:epsilonvalues}
\end{table}

After having found the region, the golden section search can begin. Algorithm~\ref{alg:goldensection} shows how it is implemented. Basically, the algorithm uses the golden ratio on our 2 borders a1 and a2 and tries to find a maximum (the highest BIC score) between these 2 values. If it exists, the section that contains the maximum is selected as new region and the search is started again, until the recursion reaches depth 3 or the condition at line~\ref{golden:condition} is fulfilled. At line~\ref{golden:calcratio},~\ref{golden:calcratio2} we calculate the 2 values a1,a2 for our golden ratio, given the region r1,r2. After that, the corresponding BIC scores f1,f2 are calculated(line~\ref{golden:bicscore},~\ref{golden:bicscore2}). If the distance between the 2 values a1,a2 is small enough, we stop the recursion and the average score between the 2 values is taken as a good $\varepsilon$ (line~\ref{golden:average}). If f1 is smaller than f2, the maximum has to be between a1 and r2 and a new golden section search is started. If it is the other way around and f1 is larger than f2, the maximum is between r1 and a2 and we start the search with these values.
If it happens that the score of f1 and f2 is exactly the same, we need to make sure, that the recursion is not endless (line ~\ref{golden:limit}). We check if f1 is larger than the largest score we already calculated. Should this be the case, the maximum is between a1 and a2 (line~\ref{golden:maxscores}). Lastly, if we do not have any luck and we have not found a maximum so far, we simply start 2 new golden searches for the left (r1, a1) and the right (a2, r2) region respectively (line~\ref{golden:leftregion},~\ref{golden:rightregion}). In the end, the algorithm returns a suggestion for a good $\varepsilon$ as shown in Table~\ref{table:goodepsilon}, which we use as input parameter ($\alpha$) for our merging algorithm.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|}
\hline
\gray &\gray 1 \\ \hline
\gray 1&64 \\ \hline
\end{tabular}
\caption{The Epsilon}
\label{table:goodepsilon}
\end{table}

\begin{algorithm}[H]
\caption{Golden\_section\_search}\label{alg:goldensection}
\begin{algorithmic}[1]
\item \textbf{Input:} region, dffa, scores
\item \textbf{Output:} good\_eps, scores, epsilon

\State $\textit{good\_eps} \gets \textit{0}$
\State $\textit{r1} \gets \textit{region(1,1)}$
\State $\textit{r2} \gets \textit{region(1,2)}$

 \While{\textit{true}}

       \State $\textit{a1} \gets \textit{r1 + 0.382(r2-r1)}$ \label{golden:calcratio}
       \State $\textit{a2} \gets \textit{r2 + 0.618(r2-r1)}$ \label{golden:calcratio2}
       \State \textit{f1} $\gets$ calculate\_BIC\_score(\textit{a1,dffa}) \label{golden:bicscore}
       \State \textit{f2} $\gets$ calculate\_BIC\_score(\textit{a2, dffa}) \label{golden:bicscore2}

         \If {\textit{|a1-a2| < 0,00001}} \label{golden:condition}
       \State $\textit{good\_eps} \gets \textit{(a1 + a2) / 2}$   \label{golden:average}
        \State \Return
       \EndIf

        \If {\textit{f1 < f2}}
        \State $\textit{region} \gets \textit{region(a1, r2)}$
        \State \textit{good\_eps, scores, epsilon} $\gets$ Golden\_section\_search(\textit{region, dffa, scores})
       \State \Return

        \ElsIf {\textit{f1 > f2}}
        \State $\textit{region} \gets \textit{region(r1, a2)}$
        \State \textit{good\_eps, scores, epsilon} $\gets$ Golden\_section\_search(\textit{region, dffa, scores)}
        \State \Return

      \Else
        \If {\textit{recursion\_depth = 3}}  \label{golden:limit}
        \State \Return
        \EndIf

        \If {\textit{f1 > max(scores)}}  \label{golden:maxscores}
        \State $\textit{new\_region} \gets \textit{a1, a2)}$
        \State \textit{good\_eps, scores, epsilon} $\gets$ Golden\_section\_search(\textit{new\_region, dffa, scores)}
        \State \Return

        \Else
          \State $\textit{regionL} \gets \textit{region(r1, a1)}$
          \State $\textit{regionR} \gets \textit{region(a2, r2)}$
        \State \textit{good\_eps, scores, epsilon} $\gets$ Golden\_section\_search(\textit{regionL, dffa, scores)} \label{golden:leftregion}
         \State \textit{good\_eps, scores, epsilon} $\gets$ Golden\_section\_search(\textit{regionR, dffa, scores)} \label{golden:rightregion}
        \State \Return
        \EndIf
       \EndIf

  \EndWhile
\end{algorithmic}
\end{algorithm}

\subsubsection{Merging }

After having calculated a good $\alpha$ value, we can finally start the AALERGIA algorithm. RED is a set of states, that is already revised, whereas BLUE is the set of states that we need to look at. The RED set starts with the initial state (line~\ref{aalergia:redstart}) and BLUE gets all its successors (line~\ref{aalergia:bluestart}). After that, we loop through all the elements of BLUE and check if we can merge it with the AALERGIA\_compatible criterion (line~\ref{aalergia:criterion}). If the states are compatible, we can merge them and the tree becomes smaller, if not, we promote the state to the RED set (line~\ref{aalergia:promote}) and exclude it from the BLUE set (line~\ref{aalergia:excludeblue}). In the end, we get a merged DFFA with a good BIC score. Further details on the AALERGIA\_compatible criterion can be found at \cite{Mao.}

\begin{algorithm}[H]
\caption{AALERGIA}\label{alg:aalergia}
\begin{algorithmic}[1]
\item \textbf{Input:}  a DFFA, a DPFA, the alpha
\item \textbf{Output:} the merged DFFA

\State $\textit{RED} \gets \textit{dffa.initial\_state}$ \label{aalergia:redstart}
\State $\textit{BLUE} \gets \textit{freq\_trans\_matrix\textsuperscript{1}(dffa.initial\_state, all)}$ \label{aalergia:bluestart}
\State \textit{promote} $\gets$ \textit{1}

 \While{BLUE is not empty}

 \State $\textit{BLUE} \gets$ sort(\textit{BLUE})
 \State $\textit{q\_b} \gets \textit{BLUE(1)}$
 \State $\textit{BLUE}$.remove\textit{(q\_b)}
 \State $\textit{same\_label\_ind} \gets $find\_same\_labels(\textit{RED, q\_b)}

 \For{$ind \in same\_label\_ind$}
        \State $\textit{q\_r} \gets \textit{RED(ind)}$
        \State $\textit{threshold} \gets$ calculate\_compatible\_params(\textit{dffa, q\_r, q\_b, alpha})

        \If {AALERGIA\_compatible(\textit{dffa, dpfa, q\_r, q\_b, alpha, threshold})} \label{aalergia:criterion}
          \State \textit{dffa\_merged} $\gets$ AALERGIA\_merge(\textit{RED, BLUE, q\_r, q\_b})
          \State \textit{promote} $\gets$ \textit{0}
          \State break
        \EndIf
\EndFor

     \If  {promote}
          \State \textit{RED} $\gets$ \textit{q\_b} and \textit{RED} \label{aalergia:promote}
        \EndIf

    \State \textit{successors} $\gets$ \textit{dffa\_merged.freq\_trans\_matrix\textsuperscript{1}}(\textit{RED, all})
    \State \textit{BLUE} $\gets$ all \textit{successors} not in \textit{RED} \label{aalergia:excludeblue}
  \EndWhile
\end{algorithmic}
\end{algorithm}

\subsubsection{Perplexity}
\me{do i need to add this or can i remove it?}


%%% Section RELATED WORK
\newpage
\section{Related Work}
This section summarizes previous and existing approaches in science, which are relevant to this paper. Furthermore, the previously mentioned PAutomaC competition, which was conducted online and focussed on learning of probabilistic automatons, is described and the implementations of the three best teams are presented.

\subsection{Probabilistic machine learning}
In order to learn probabilistic models, which are perfectly suited for learning real systems in a physical environment, Sen et al.~\cite{Sen2004} adapted the algorithm of \cite{Carrasco.1994} and presented a novel approach for learning continuous time Markov chain models. However, one limitation of their work is that the algorithm doesn't scale up for large underlying blackbox models. Mao et al.~\cite{Mao.} wrote the paper that presented AALERGIA and proved a strong theoretical and experimental consistency with their results. One year later, Mao et al.~\cite{Mao.2012} wrote a paper about learning Markov decision processes for model checking, however, their results need further research, as the algorithm is not suitable for routine use yet.

\subsection{Model checking}
Model checking is used to make sure that certain properties hold in a given model of a system. It is used for exhaustive and automatic verification of a property in a finite state system. PRISM \me{citation!} model checker has been used for model checking for many network protocols successfully: Duflot et al.~\cite{DKNP06} used probabilistic model checking to compute the performance of different device discovery scenarios in the Bluetooth wireless communication protocol. They managed to perform an exhaustive low level analysis and examined the run times (best and worst) of the protocol, but were limited by the size of the probabilistic models that were needed. In order to cope with this problem, combination with simulation or abstraction and symmetry reduction methods are proposed.
Kwiatkowska et al.~\cite{KNSW07} performed probabilistic model checking techniques on the CSMA/CD communication protocol and the IEEE1394 FireWire root contention protocol. They give an overview about probabilistic temporal-logic properties of wireless networks~\cite{KNP09a}.
Matthias Fruth~\cite{Fru06} modelled the IEEE 802.15.4 standard in PRISM model checker and verified correctness properties, like the successful transmission or the amount of collisions, on it.

\subsection{PAutomaC online challenge}
The PAutomaC online challenge~\cite{Verwer.2014} was conducted in 2012 and its goal was to find the best performing model/algorithm for learning probabilistic automatons. The competition provided different distribution sets, generated from various models with different sizes and ranges. The participants had access to artificially generated training and test sets, which they could use to learn the corresponding string distributions. The learned data structure was not evaluated, so the use of any learning method was allowed. Furthermore, the competition included two real world data sets. As stated on their website, the competition had 38 participants, but only five managed to score points. The clear winner of the competition is team Shibata Yoshinaka~\cite{Shibata_the11th}.

Team Kepler~\cite{Kepler} used variable length N-grams to learn the automatons. They created a tree structure, which they used to store the contexts with variable length. After having inserted all the sequences into the tree, they pruned it with the help of the Kullback-Leibler divergence between the leave and the parent. They managed to produce better results than the 3 gram algorithm, which was provided by the competition.
Another interesting approach was submitted by team Hulden~\cite{MansHulden.2012}. The team implemented a tool called 'treba', which uses a variant of the Baum-Welch algorithm to train a probabilistic finite automaton. They put strong focus on the numerical stability and the parallelization of the algorithm. Their contribution managed to gain a few points in the competition and performed best on dense instances with few states~\cite{Verwer.2014}.

The winning team Shibata Yoshinaka~\cite{Shibata_the11th} obtained the best perplexity values on most instances. The more data they had, the better their perplexity values became, which indicates, that they make good use of more data. They implemented different algorithms but concluded, that their version of \textit{Collabsed Gibbs Sampling (CGS)}, which is a Bayesian method for sampling, works best on the data. For PDFAs they implemented a state-merging algorithm which is based on the marginal probability. Among the presented algorithms, CGS performed best, but had quite high computational cost. It performs best when there are many strings (100k) or the target contains few (<21) states.

\me{The continue the discussion on SHIBATA and why it is winning every major contest in this field  PAutomataC 2012, CONTEST 2016.}

\newpage
\section{Implementation of the AALERGIA algorithm in python}


\section{Implementation of the IEEE 802.15.4 PRISM model}
In order to test our implementation of AALERGIA in python, we decided to learn a simple model of the IEEE 802.15.4 unslotted protocol. The concept of the model was taken from the paper of Wu et al.~\cite{stability}, but the PRISM model was implemented by us. The model originally was considered to be a probabilistic timed automaton (PTA). However, since PRISM model checker only provides limited support for PTAs, we cannot generate traces out of them. Fortunately, there is a way around that issue. It is possible to convert the PTA to a finite state Markov decision process, using the digital clocks approach presented in the paper of Kwiatkowska et al.~\cite{KNPS06}.

A wireless network control system (WNCS) with two sending modules and one channel module in parallel composition is considered. The two sending modules start their sending process at the same time. They access the channel according to the unslotted CSMA/CA protocol. The protocol uses a mechanism called exponential backoff. A sender listens to the channel before sending. If the channel is busy, it waits a random amount of time, before attempting to send again. Since we are modelling a MDP, we need to work with discrete time. The smallest unit of time in our model is balled backoff period \textit{T\textsubscript{b}}. If the sender wants to send a packet, it needs to initialise the variables \textit{NB} and \textit{BE}. Each sender might have different \textit{BE} and \textit{NB} values during its sending process. \textit{NB} denotes the number of times a backoff was required (due to a busy channel). The upper bound is called \textit{NB\textsubscript{max}}. \textit{BE} describes the backoff-exponent and is related to the random amount of time the sender waits before it attempts to listen to the channel again. \textit{BE} is initially set to \textit{BE\textsubscript{min}} and the upper bound is \textit{BE\textsubscript{max}}.

Figure~\ref{IEEE802:pdf} shows, how the sender (a) and the channel (b) are modelled.

\begin{figure}[ht!]
  \centering
\includegraphics[page=1]{data/stability_cropped.pdf}
\caption{The concept of the sender and the channel}
\label{IEEE802:pdf}
\end{figure}
\me{CITE THE IMAGE CORRECTLY}

The sender starts by setting the backoff time, which is discrete and chosen randomly between 0\textit{T\textsubscript{B}} and ($2^{BE_{min}} - 1$)\textit{T\textsubscript{B}}. After that, it enters a state where it waits for the backoff time to expire. Next, the sender listens to the channel, this takes \textit{T\textsubscript{CCA}} time. From there on, three transitions can be taken. If the channel is busy and the number of backoff times \textit{NB} is equal to \textit{NB\textsubscript{max}}, the module ends in the state \textit{FAILURE} and stays there. However, if the channel is busy but \textit{NB} is smaller than \textit{NB\textsubscript{max}}, the sending module starts with its first state again. Additionally, \textit{BE} is increased by one, which increases the chance for a longer backoff time. \textit{NB} is also increased by one, noting that one more backoff attempt is started. Last but not least, if the channel is idle, the sender can start sending the packet. Once the process is finished, it remains in the state \textit{DONE}.

The channel module is simple as well. It implements two states, \textit{c1} and \textit{c2}, that indicate the channel condition. If $c1=c2=0$, the channel is idle. If $c1=1$ or $c2=1$, either \textit{c1} or \textit{c2} are sending. If both of the sending modules are attempting to send at the same time, $c1=c2=2$ and the process failed due to a collision.

The source code of the PRISM model for the channel is shown in Figure~\ref{fig:channelmodel}.

\begin{figure}[ht!]
\begin{lstlisting}[language=Prism, ,escapechar=|]

module channel
	c1 : [0..2] init 0;
	c2 : [0..2] init 0;

	[send1] c1=0 & c2=0 -> (c1'=1);
	[send2] c2=0 & c1=0 -> (c2'=1);

	// check if something is sent -> collision!
	[send1] c1=0 & c2>0 -> (c1'=2) & (c2'=2);
	[send2] c2=0 & c1>0 -> (c1'=2) & (c2'=2);

	// message was sent and channel is clear again
	[finish1] c1>0 -> (c1'=0);
	[finish2] c2>0 -> (c2'=0);
endmodule

\end{lstlisting}
\caption{The PRISM Channel Model for IEEE 802.15.4 unslotted}
\label{fig:channelmodel}
\end{figure}

The source code of the PRISM model for the sender is shown in Figure~\ref{fig:sendermodel}. The code depicts, in the PRISM coding language, the various guards, which are used to decide which states can be reached in the next step. The sender has a clock \textit{x}, which is increasing during each time step and has a maximum value of \textit{SAMPLING\_TIME}, which is 80 by default. The guards where \textit{s=2} model the non determinism of the packet length, that varies from 20-30\textit{T\textsubscript{B}}.

\begin{figure}[H]
\begin{lstlisting}[language=Prism, ,escapechar=|]

module sender1

	NB : [0..NB_MAX] init 0;
	BE : [0..BE_MAX] init BE_MIN;
	BOFF_DELAY : [0..BOFF_DELAY_MAX];

	DL : [0..DL_MAX] init DL_MAX;

	s : [0..5] init 0; // location
	// 0 : SET BACKOFF TIME
	// 1 : BACKOFF
	// 2 : CCA
	// 3 : DATA TRANSMISSION
	// 4 : DONE
	// 5 : FAILED

	x : [0..SAMPLING_TIME] init 0; // clock

	[] s = 0 & BE=1 -> (1/2):(s'=1) & ...;
	[] s = 0 & BE=2 -> (1/4):(s'=1) & ...;
	[] s = 0 & BE=3 -> (1/8):(s'=1) & ...;
	[] s = 0 & BE=4 -> (1/16):(s'=1) & ...;
	[] s = 0 & BE=5 -> (1/32):(s'=1) & ...;
	[] s = 0 & BE=6 -> (1/64):(s'=1) & ...;

	[time] s=1 & x < TB -> (x'=min(x+1,SAMPLING_TIME));
	[] s=1 & x = TB & BOFF_DELAY > 0 -> (s'=1) & (x'=0) & (BOFF_DELAY'=BOFF_DELAY-1);
	[] s=1 & x = TB & BOFF_DELAY = 0 -> (s'=2) & (x'=0);

	[time] s=2 & x < TCCA -> (x'=min(x+1,SAMPLING_TIME));
	
	[] s=2 & x = TCCA & ch_busy & NB < NB_MAX  -> (x'=0) & (NB' = min(NB+1, NB_MAX)) & (BE' = min(BE+1, BE_MAX)) & (s'=0);
	[] s=2 & x = TCCA & ch_busy & NB = NB_MAX  -> (s'=5);

	// Move to next state, set nondeterministic data_length
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-10);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-9);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-8);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-7);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-6);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-5);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-4);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-3);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-2);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-1);
	[send1] s=2 & x = TCCA & ch_free -> (x'=0) & (s'=3) & (DL'=DL_MAX-0);

	[time] s=3 & x < DATA_LENGTH -> (x'=min(x+1,SAMPLING_TIME));
	[finish1] s=3 & x = DATA_LENGTH & ch_busy -> (s'=4);

	[time] s = 4 -> (s'=4); // FINISHED, stay here

	[time] s = 5 -> (s'=5); // FAILED, stay here
endmodule

\end{lstlisting}
\caption{The PRISM Sender Model for IEEE 802.15.4 unslotted}
\label{fig:sendermodel}
\end{figure}

\newpage
\section{Generating traces of the model and learning the model with AALERGIA}
In order to generate traces out of the PRISM model we mentioned in the previous section, some reflections need to be done. It is especially important to think about how the states can be represented in the traces and how the alphabet looks like. The level of detail can be abstracted or more refined. For the final model, the discrete time Markov chain created by AALERGIA, only the time steps in the MDP are essential. This allows us to filter all the steps in the traces, that are not related to changes in time.

When we look at our system, only the states of the two senders and the state of the channel is of importance. This is represented by a symbol that depicts the state of the first sender, the state of the second sender, the channel condition 1 and the channel condition 2 in a row. Every symbol stands for a time step and all the symbols in a trace are seperated by commas. A random example of these traces is shown in table~\ref{table:tracemodel}. For instance, a symbol like \textit{1301} shows, that sender 1 is in state 1, sender 2 is in state 3, channel condition 1 is in state 0 and channel condition 2 is in state 1. If we look at our model, this means, that sender 2 is sending and sender 1 is waiting.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|}
\hline
\gray & \gray  1                                 \\ \hline
\gray 1&0000,1100,2100,3110,3110,3110,3210,3110,3110,3110,3110,3110,3110,3210,3110,3110,3110, \\
\hline
\gray 2&0000,1100,1100,1100,1100,1100,1200,1301,1301,2301,1301,2301,1301,2301,1301,2301,1301, \\
\hline
\gray 3&0000,1100,1100,1200,1301,1301,2301,1301,2301,1301,1301,1301,1301,1301,1301,2301,1301, \\
\hline
\end{tabular}
\caption{The Traces of the IEEE 802.15.4 protocol}
\label{table:tracemodel}
\end{table}

In order to create the DTMC, AALERGIA needs an alphabet as well. The full alphabet contains all the symbols that can occur in the traces and is contained in a seperate file. An example is given in table~\ref{table:alphmodel}.

\begin{table}[ht!]
\centering
\begin{tabular}{|l|l|}
\hline
\gray & \gray  1                                 \\ \hline
\gray 1&0000 \\
\hline
\gray 2&1100 \\
\hline
\gray 3&2100 \\
\hline
\gray 3&3110 \\
\hline
\gray 3&3210 \\
\hline
\gray 3&4301 \\
\hline
\gray 3&1200 \\
\hline
\gray 3&2301 \\
\hline
\end{tabular}
\caption{A Sample of the alphabet of the IEEE 802.15.4 protocol}
\label{table:alphmodel}
\end{table}


\section{Evaluation}
\me{descirbe the value of sample period, describe the PR measure, describe the random packet length...}
\me{how well did the idea work? experimental setup, results...}


After learning the DTMC model with AALERGIA, the results need to be compared by model checking. The initial question Wu et al.~\cite{stability} tried to answer with probabilistic model checking was, whether the network is stable or not. For this reason, they defined the minimum probability they are interested in as follows:
\begin{itemize}
  \item \textit{PR = The minimum probability of both stations successfully transmitting their packets within one sampling period}
\end{itemize}

This can be checked by satisfying the stability specification:
\begin{itemize}
  \item $\mathcal{P}_{\geq1-p}$ [true $\mathcal{U}$ (done1 $\land$ done2 $\land$ z $\leq$h)]
\end{itemize}

We compared the minimum probability Wu et al. with their setup got as a result to the result we got with our model and after we applied ALLERGIA on the DTMC.

\centering
	\begin{tikzpicture}
		\begin{axis}[ymin=0, xlabel={BE\textsubscript{min}}, ylabel={PR}, legend entries={PTA,MDP,DTMC}, legend style={at={(1,1)},anchor=north west,nodes=right}]
			\addplot table {data/be_min_paper.csv};
            \addplot table {data/be_min_model.csv};
            \addplot table {data/be_min_learned.csv};
		\end{axis}
	\end{tikzpicture}

	\begin{tikzpicture}
		\begin{axis}[ymin=0, xlabel={BE\textsubscript{max}}, xtick={3,4,5,6}, ylabel={PR}, legend entries={PTA,MDP,DTMC}, legend style={at={(1,1)},anchor=north west,nodes=right}]
			\addplot table {data/be_max_paper.csv};
            \addplot table {data/be_max_model.csv};
            \addplot table {data/be_max_learned.csv};
		\end{axis}
	\end{tikzpicture}

	\begin{tikzpicture}
		\begin{axis}[ymin=0, xlabel={NB\textsubscript{max}}, ylabel={PR}, legend entries={PTA,MDP,DTMC}, legend style={at={(1,1)},anchor=north west,nodes=right}]
			\addplot table {data/nb_max_paper.csv};
			\addplot table {data/nb_max_model.csv};
			\addplot table {data/nb_max_learned.csv};
		\end{axis}
	\end{tikzpicture}

\newpage
\section{Conclusions}
\me{the approach is good; but! state advantages and disadvantages, no new infos!}

\appendix
 \bibliographystyle{ieeetr}
 \bibliography{sources}

\end{document} 